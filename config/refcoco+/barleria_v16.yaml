DATA:
  dataset: refcoco+
  train_lmdb: datasets/lmdb/refcoco+/train.lmdb
  train_split: train
  val_lmdb: datasets/lmdb/refcoco+/testB.lmdb
  val_split: testB
  mask_root: datasets/masks/refcoco+
TRAIN:
  # Base Arch
  clip_pretrain: pretrain/ViT-B-16.pt
  model_name: CLIP-b-16
  input_size: 416
  word_len: 17
  word_dim: 512
  ladder_dim: 64
  nhead: 8
  multi_stage: 3
  stride: [1, 1, 1]
  vis_dim: 512
  fpn_in: [768, 768, 512]
  fpn_out: [256, 512, 1024]
  sync_bn: True
  use_snf: True
  use_txt_add: False
  use_side: True
  flow_length: 4
  snf_method: normalization_flow
  # Decoder
  num_layers: 3
  num_head: 8
  dim_ffn: 512
  dropout: 0.1
  intermediate: False
  # Training Setting
  workers: 32  # data loader workers
  workers_val: 16
  epochs: 50
  milestones: [35]
  start_epoch: 0
  batch_size: 32  # batch size for training
  batch_size_val: 32  # batch size for validation during training, memory and speed tradeoff
  base_lr: 0.0001
  lr_decay: 0.1
  lr_multi: 1
  weight_decay: 0.
  max_norm: 0.
  manual_seed: 0
  print_freq: 100
  # Resume & Save
  exp_name: B_V16
  output_folder: exp/refcoco+
  save_freq: 1
  weight:  # path to initial weight (default: none)
  resume:  # path to latest checkpoint (default: none)
  evaluate: True  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend
Distributed:
  dist_url: tcp://localhost:3681
  dist_backend: 'nccl'
  multiprocessing_distributed: True
  world_size: 1
  rank: 0
TEST:
  test_split: val-test
  test_lmdb: datasets/lmdb/refcoco/val.lmdb
  visualize: False
Model:
  SIDE_ADAPTER:
    NAME: "RegionwiseSideAdapterNetwork"
    VIT_NAME: "absvit_tiny_patch16_224"
    PRETRAINED: False
    IMAGE_SIZE: 416
    DROP_PATH_RATE: 0.0
    NUM_QUERIES: 128
    FUSION_TYPE: "add"
    FUSION_MAP: ["0->0", "3->1", "6->2", "9->3"]
    DEEP_SUPERVISION_IDXS: [8]
    ATTN_BIAS:
      NUM_HEADS: 12
      NUM_LAYERS: 1
      EMBED_CHANNELS: 512
      MLP_CHANNELS: 256
      MLP_NUM_LAYERS: 3
      RESCALE_ATTN_BIAS: True